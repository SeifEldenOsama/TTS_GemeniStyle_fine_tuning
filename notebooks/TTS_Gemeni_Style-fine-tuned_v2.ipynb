{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e76873a",
   "metadata": {},
   "source": [
    "# Welcome to Modal notebooks!\n",
    "\n",
    "Write Python code and collaborate in real time. Your code runs in Modal's\n",
    "**serverless cloud**, and anyone in the same workspace can join.\n",
    "\n",
    "This notebook comes with some common Python libraries installed. Run\n",
    "cells with `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e45adaf2",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!modal secret create kaggle-secret \\\n",
    "    KAGGLE_USERNAME=seifosamahosney \\\n",
    "    KAGGLE_KEY=<REDACTED_KAGGLE_KEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a4114fa",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile download_tts_simple.py\n",
    "import modal\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "app = modal.App(\"download-tts-fixed\")\n",
    "\n",
    "volume = modal.Volume.from_name(\"tts-dataset-storage\", create_if_missing=True)\n",
    "\n",
    "@app.function(\n",
    "    image=modal.Image.debian_slim().pip_install(\"kaggle\"),\n",
    "    secrets=[modal.Secret.from_name(\"kaggle-secret\")],\n",
    "    volumes={\"/data\": volume},\n",
    "    timeout=3600,\n",
    ")\n",
    "def download_to_volume():\n",
    "    \"\"\"Download Kaggle TTS dataset and structure it correctly\"\"\"\n",
    "\n",
    "    # Target structure (Parler-TTS compatible)\n",
    "    target_dir = Path(\"/data/tts_dataset/teacher_dataset_large_updated\")\n",
    "    voices_dir = target_dir / \"voices\"\n",
    "\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    voices_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Temp download location\n",
    "    temp_download_path = Path(\"/tmp/kaggle_data\")\n",
    "    temp_download_path.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading Kaggle dataset to {temp_download_path}...\")\n",
    "\n",
    "    # Download + unzip\n",
    "    cmd = [\n",
    "        \"kaggle\", \"datasets\", \"download\",\n",
    "        \"-d\", \"seifosamahosney/tts-dataset\",\n",
    "        \"-p\", str(temp_download_path),\n",
    "        \"--unzip\",\n",
    "        \"--force\",\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Kaggle Error:\\n{result.stderr}\")\n",
    "        return \"Download failed\"\n",
    "\n",
    "    print(\"Download successful! Locating dataset files...\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Locate voices directory\n",
    "    # -------------------------\n",
    "    voices_dirs = list(temp_download_path.rglob(\"voices\"))\n",
    "\n",
    "    if not voices_dirs:\n",
    "        print(\"voices folder not found anywhere!\")\n",
    "        print(\"Extracted contents:\")\n",
    "        for p in temp_download_path.rglob(\"*\"):\n",
    "            print(\" -\", p)\n",
    "        return \"voices folder missing\"\n",
    "\n",
    "    source_voices_dir = voices_dirs[0]\n",
    "    print(f\"Found voices folder at: {source_voices_dir}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Move wav files\n",
    "    # -------------------------\n",
    "    count = 0\n",
    "    for wav_file in source_voices_dir.rglob(\"*.wav\"):\n",
    "        target_file = voices_dir / wav_file.name\n",
    "        if not target_file.exists():\n",
    "            shutil.move(str(wav_file), str(target_file))\n",
    "            count += 1\n",
    "\n",
    "    print(f\"Moved {count} .wav files to {voices_dir}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Locate & move metadata\n",
    "    # -------------------------\n",
    "    metadata_files = list(temp_download_path.rglob(\"metadata.jsonl\"))\n",
    "    metadata_dst = target_dir / \"metadata.jsonl\"\n",
    "\n",
    "    if metadata_files:\n",
    "        shutil.move(str(metadata_files[0]), str(metadata_dst))\n",
    "        print(f\"Moved metadata.jsonl to {metadata_dst}\")\n",
    "    else:\n",
    "        print(\"metadata.jsonl not found\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Verification\n",
    "    # -------------------------\n",
    "    has_wavs = any(voices_dir.glob(\"*.wav\"))\n",
    "    has_metadata = metadata_dst.exists()\n",
    "\n",
    "    print(f\"WAV files present: {has_wavs}\")\n",
    "    print(f\"Metadata present: {has_metadata}\")\n",
    "\n",
    "    volume.commit()\n",
    "    print(\"Saved to permanent volume 'tts-dataset-storage'\")\n",
    "\n",
    "    return f\"Dataset ready at {target_dir}\"\n",
    "\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "    download_to_volume.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41fe59ea",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!modal run download_tts_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47816ee1",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!modal secret create hf-secret HF_TOKEN=<REDACTED_HF_TOKEN> # you must give it access to write and read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0101a31",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile train_parler.py\n",
    "import modal\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "GPU_CONFIG = \"H100:1\"\n",
    "NUM_GPUS = 1\n",
    "\n",
    "VOLUME_NAME = \"tts-dataset-storage\"\n",
    "MOUNT_PATH = Path(\"/data\")\n",
    "OUTPUT_DIR = MOUNT_PATH / \"parler-tts-finetuned-h100\"\n",
    "HF_DATASET_REPO = \"SeifElden2342532/parler-tts-dataset-format\"\n",
    "\n",
    "# -------------------------\n",
    "# DEPENDENCIES (H100 SAFE)\n",
    "# -------------------------\n",
    "REQUIREMENTS = [\n",
    "    \"torch==2.4.1\",\n",
    "    \"torchaudio==2.4.1\",\n",
    "    \"accelerate\",\n",
    "    \"datasets[audio]\",\n",
    "    \"transformers==4.46.1\",\n",
    "    \"pydantic==1.10.17\",\n",
    "    \"tqdm\",\n",
    "    \"soundfile\",\n",
    "    \"scipy\",\n",
    "    \"pyyaml\",\n",
    "    \"protobuf==4.25.8\",\n",
    "    \"wandb\",\n",
    "    \"evaluate\",\n",
    "    \"jiwer\",\n",
    "    \"librosa\",\n",
    "    \"bitsandbytes\",\n",
    "    \"huggingface_hub\",\n",
    "    \"parler-tts @ git+https://github.com/huggingface/parler-tts.git\",\n",
    "]\n",
    "\n",
    "image = (\n",
    "    modal.Image.from_registry(\n",
    "        \"nvidia/cuda:12.1.1-devel-ubuntu22.04\",\n",
    "        add_python=\"3.11\",\n",
    "    )\n",
    "    .apt_install(\"git\", \"ffmpeg\", \"libsndfile1\")\n",
    "    .run_commands(\"ulimit -n 65536\")\n",
    "    .pip_install(\n",
    "        *REQUIREMENTS,\n",
    "        extra_index_url=\"https://download.pytorch.org/whl/cu121\",\n",
    "    )\n",
    ")\n",
    "\n",
    "app = modal.App(\n",
    "    \"parler-tts-h100-finetune\",\n",
    "    image=image,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# TRAIN FUNCTION\n",
    "# -------------------------\n",
    "@app.function(\n",
    "    volumes={str(MOUNT_PATH): modal.Volume.from_name(VOLUME_NAME)},\n",
    "    timeout=25000,\n",
    "    gpu=GPU_CONFIG,\n",
    "    env={\n",
    "        \"FORCE_LIBSNDFILE\": \"1\",\n",
    "        \"HF_AUDIO_DISABLE_TORCHCODEC\": \"1\",\n",
    "    },\n",
    ")\n",
    "def finetune_parler_tts():\n",
    "    repo_path = Path(\"/root/parler-tts\")\n",
    "\n",
    "    if not repo_path.exists():\n",
    "        print(\"Cloning Parler-TTS repository...\")\n",
    "        subprocess.run(\n",
    "            [\"git\", \"clone\", \"https://github.com/huggingface/parler-tts.git\", str(repo_path)],\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "    # -------------------------\n",
    "    # PATCH KNOWN PARLER-TTS BUGS\n",
    "    # -------------------------\n",
    "    import training.data\n",
    "\n",
    "    data_py_path = Path(training.data.__file__)\n",
    "    content = data_py_path.read_text()\n",
    "\n",
    "    buggy_code = (\n",
    "        'metadata_dataset_names = metadata_dataset_names.split(\"+\") '\n",
    "        'if metadata_dataset_names is not None else None'\n",
    "    )\n",
    "    fixed_code = (\n",
    "        'metadata_dataset_names = metadata_dataset_names.split(\"+\") '\n",
    "        'if (metadata_dataset_names is not None and isinstance(metadata_dataset_names, str)) '\n",
    "        'else [None] * len(dataset_names)'\n",
    "    )\n",
    "    if buggy_code in content:\n",
    "        content = content.replace(buggy_code, fixed_code)\n",
    "\n",
    "    buggy_eval_code = 'vectorized_datasets[\"validation\"]'\n",
    "    fixed_eval_code = 'vectorized_datasets[\"eval\"]'\n",
    "    if buggy_eval_code in content:\n",
    "        content = content.replace(buggy_eval_code, fixed_eval_code)\n",
    "\n",
    "    data_py_path.write_text(content)\n",
    "\n",
    "    training_script_path = repo_path / \"training\" / \"run_parler_tts_training.py\"\n",
    "    script_content = training_script_path.read_text()\n",
    "\n",
    "    buggy_num_proc = (\n",
    "        'num_proc=min(data_args.preprocessing_num_workers, '\n",
    "        'len(vectorized_datasets[\"eval\"]) - 1),'\n",
    "    )\n",
    "    fixed_num_proc = \"num_proc=1,\"\n",
    "    if buggy_num_proc in script_content:\n",
    "        script_content = script_content.replace(buggy_num_proc, fixed_num_proc)\n",
    "\n",
    "    training_script_path.write_text(script_content)\n",
    "\n",
    "    # -------------------------\n",
    "    # TRAINING COMMAND\n",
    "    # -------------------------\n",
    "    model_name = \"parler-tts/parler-tts-mini-v1\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    training_command = f\"\"\"\n",
    "accelerate launch --num_processes={NUM_GPUS} training/run_parler_tts_training.py \\\\\n",
    "  --model_name_or_path \"{model_name}\" \\\\\n",
    "  --train_dataset_name \"{HF_DATASET_REPO}\" \\\\\n",
    "  --train_dataset_config_name \"default\" \\\\\n",
    "  --train_split_name \"train\" \\\\\n",
    "  --eval_dataset_name \"{HF_DATASET_REPO}\" \\\\\n",
    "  --eval_dataset_config_name \"default\" \\\\\n",
    "  --eval_split_name \"validation\" \\\\\n",
    "  --max_train_samples 2000 \\\\\n",
    "  --max_eval_samples 200 \\\\\n",
    "  --seed 42 \\\\\n",
    "  --do_train true \\\\\n",
    "  --do_eval true \\\\\n",
    "  --preprocessing_num_workers 1 \\\\\n",
    "  --evaluation_strategy \"epoch\" \\\\\n",
    "  --description_column_name \"text_description\" \\\\\n",
    "  --prompt_column_name \"text\" \\\\\n",
    "  --target_audio_column_name \"audio\" \\\\\n",
    "  --description_tokenizer_name \"google/flan-t5-base\" \\\\\n",
    "  --prompt_tokenizer_name \"google/flan-t5-base\" \\\\\n",
    "  --save_to_disk \"/tmp/parler_dataset_processed\" \\\\\n",
    "  --temporary_save_to_disk \"/tmp/parler_dataset_temp\" \\\\\n",
    "  --output_dir \"{OUTPUT_DIR}\" \\\\\n",
    "  --overwrite_output_dir true \\\\\n",
    "  --per_device_train_batch_size 8 \\\\\n",
    "  --per_device_eval_batch_size 8 \\\\\n",
    "  --gradient_accumulation_steps 2 \\\\\n",
    "  --gradient_checkpointing true \\\\\n",
    "  --optim \"adamw_bnb_8bit\" \\\\\n",
    "  --max_steps 400 \\\\\n",
    "  --bf16 true \\\\\n",
    "  --report_to \"none\"\n",
    "\"\"\"\n",
    "\n",
    "    print(\"\\nStarting Parler-TTS fine-tuning on H100â€¦\")\n",
    "    subprocess.run(training_command, shell=True, check=True, cwd=str(repo_path))\n",
    "\n",
    "    modal.Volume.from_name(VOLUME_NAME).commit()\n",
    "    print(\"\\nFine-tuning complete!\")\n",
    "\n",
    "# -------------------------\n",
    "# ENTRYPOINT\n",
    "# -------------------------\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "    finetune_parler_tts.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2474503b",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!modal run train_parler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91466b1f",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile compare_models.py\n",
    "import modal\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "GPU_CONFIG = \"H100:1\"\n",
    "VOLUME_NAME = \"tts-dataset-storage\"\n",
    "MOUNT_PATH = Path(\"/data\")\n",
    "FINETUNED_MODEL_PATH = MOUNT_PATH / \"parler-tts-finetuned-h100\"\n",
    "BASE_MODEL_NAME = \"parler-tts/parler-tts-mini-v1\"\n",
    "\n",
    "REQUIREMENTS = [\n",
    "    \"torch==2.4.1\",\n",
    "    \"torchaudio==2.4.1\",\n",
    "    \"transformers==4.46.1\",\n",
    "    \"parler-tts @ git+https://github.com/huggingface/parler-tts.git\",\n",
    "    \"soundfile\",\n",
    "    \"scipy\",\n",
    "]\n",
    "\n",
    "image = (\n",
    "    modal.Image.from_registry(\n",
    "        \"nvidia/cuda:12.1.1-devel-ubuntu22.04\",\n",
    "        add_python=\"3.11\",\n",
    "    )\n",
    "    .apt_install(\"git\", \"ffmpeg\", \"libsndfile1\")\n",
    "    .pip_install(\n",
    "        *REQUIREMENTS,\n",
    "        extra_index_url=\"https://download.pytorch.org/whl/cu121\",\n",
    "    )\n",
    ")\n",
    "\n",
    "app = modal.App(\"parler-tts-comparison\", image=image)\n",
    "\n",
    "@app.function(\n",
    "    volumes={str(MOUNT_PATH): modal.Volume.from_name(VOLUME_NAME)},\n",
    "    gpu=GPU_CONFIG,\n",
    "    timeout=600,\n",
    "    env={\n",
    "        \"FORCE_LIBSNDFILE\": \"1\",\n",
    "        \"HF_AUDIO_DISABLE_TORCHCODEC\": \"1\",\n",
    "    },\n",
    ")\n",
    "def run_comparison(prompt: str, description: str):\n",
    "    import torch\n",
    "    from parler_tts import ParlerTTSForConditionalGeneration\n",
    "    from transformers import AutoTokenizer\n",
    "    import soundfile as sf\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def generate_audio(model_id, label):\n",
    "        print(f\"Loading {label} modelâ€¦\")\n",
    "        model = ParlerTTSForConditionalGeneration.from_pretrained(model_id).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        prompt_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        description_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            input_ids = description_tokenizer(\n",
    "                description, return_tensors=\"pt\"\n",
    "            ).input_ids.to(device)\n",
    "\n",
    "            prompt_input_ids = prompt_tokenizer(\n",
    "                prompt, return_tensors=\"pt\"\n",
    "            ).input_ids.to(device)\n",
    "\n",
    "            audio = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                prompt_input_ids=prompt_input_ids,\n",
    "            )\n",
    "\n",
    "        audio_arr = audio.cpu().numpy().squeeze()\n",
    "        filename = f\"output_{label.lower().replace(' ', '_')}.wav\"\n",
    "        sf.write(filename, audio_arr, model.config.sampling_rate)\n",
    "\n",
    "        with open(filename, \"rb\") as f:\n",
    "            return f.read(), filename\n",
    "\n",
    "    base_audio, base_file = generate_audio(BASE_MODEL_NAME, \"Base\")\n",
    "\n",
    "    if not FINETUNED_MODEL_PATH.exists():\n",
    "        return f\"Fine-tuned model not found at {FINETUNED_MODEL_PATH}\", None\n",
    "\n",
    "    ft_audio, ft_file = generate_audio(str(FINETUNED_MODEL_PATH), \"Fine-tuned\")\n",
    "\n",
    "    return {\n",
    "        \"base\": (base_audio, base_file),\n",
    "        \"finetuned\": (ft_audio, ft_file),\n",
    "    }\n",
    "\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "    test_prompt = (\n",
    "        \"Well, when you play super hard, your muscles get tiny little changes that make them feel a bit tired. But don't you worry, those changes are actually helping them get stronger so you can play even more!\"\n",
    "    )\n",
    "    test_description = (\n",
    "        \"A male speaker delivers a gentle and moderate-paced speech. The recording is clean with a natural quality. The voice has a neutral pitch.\"\n",
    "    )\n",
    "\n",
    "    print(\"ðŸŽ§ Starting comparison inferenceâ€¦\")\n",
    "    results = run_comparison.remote(test_prompt, test_description)\n",
    "\n",
    "    if isinstance(results, str):\n",
    "        print(results)\n",
    "        return\n",
    "\n",
    "    for key, (audio_data, filename) in results.items():\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(audio_data)\n",
    "        print(f\"Saved {key} result to {filename}\")\n",
    "\n",
    "    print(\"\\nComparison complete! Listen to both files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e094bc6",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!modal run compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c36e9f",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
